{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ede4c4",
   "metadata": {},
   "source": [
    "## Preprocessing and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3c9d510e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lilia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/lilia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad22b06",
   "metadata": {},
   "source": [
    "### Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8261e661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nm/b7tk3rjx5vnb02jr8x3zr64r0000gn/T/ipykernel_2891/4285653672.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv(\"train_data.txt\", delimiter = ' ::: ', header = None, names = ['ID', 'TITLE', 'GENRE', 'DESCRIPTION'])\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/train_data.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# data = pd.read_csv(dataset_path, sep=':::', engine='python', header=None)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# data.columns = ['ID', 'TITLE', 'GENRE', 'DESCRIPTION']\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_data.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, delimiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ::: \u001b[39m\u001b[38;5;124m'\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTITLE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGENRE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDESCRIPTION\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DM_ENV/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DM_ENV/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DM_ENV/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DM_ENV/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DM_ENV/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_data.txt'"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "dataset_path = 'data/train_data.txt'\n",
    "# data = pd.read_csv(dataset_path, sep=':::', engine='python', header=None)\n",
    "# data.columns = ['ID', 'TITLE', 'GENRE', 'DESCRIPTION']\n",
    "data = pd.read_csv(\"train_data.txt\", delimiter = ' ::: ', header = None, names = ['ID', 'TITLE', 'GENRE', 'DESCRIPTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd658d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Number of instances = %d' % (data.shape[0]))\n",
    "print('Number of attributes = %d' % (data.shape[1]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe45ba7",
   "metadata": {},
   "source": [
    "#### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3ee1cc02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                        int64\n",
       "TITLE                    object\n",
       "GENRE                    object\n",
       "DESCRIPTION              object\n",
       "CLEAN_DESCRIPTION        object\n",
       "TOKENIZED_DESCRIPTION    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing data types of DataFrame\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b5666",
   "metadata": {},
   "source": [
    "#### Dataframe Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c3b48ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>54214.0</td>\n",
       "      <td>27107.5</td>\n",
       "      <td>15650.378084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13554.25</td>\n",
       "      <td>27107.5</td>\n",
       "      <td>40660.75</td>\n",
       "      <td>54214.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count     mean           std  min       25%      50%       75%      max\n",
       "ID  54214.0  27107.5  15650.378084  1.0  13554.25  27107.5  40660.75  54214.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing description of DataFrame\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa267f8",
   "metadata": {},
   "source": [
    "#           Data Cleaning and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5967a",
   "metadata": {},
   "source": [
    " ### Removing HTML tags if the data is scraped from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9f20465a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    clean_text = re.sub(r'<[^>]+>', '', text)\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2509f",
   "metadata": {},
   "source": [
    " ### Removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "97cabf79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b7e025",
   "metadata": {},
   "source": [
    " ### Removing emojis and  non-standard symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5ffeb664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a regex pattern to match emojis and non-standard symbols\n",
    "# This pattern targets characters outside the typical ASCII range, which includes most emojis and non-standard symbols\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                           u\"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# Function to remove emojis and non-standard symbols\n",
    "def remove_emojis_and_symbols(text):\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Apply the function to remove emojis and non-standard symbols from DESCRIPTION\n",
    "data['DESCRIPTION'] = data['DESCRIPTION'].apply(remove_emojis_and_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6942c",
   "metadata": {},
   "source": [
    "###   Converting to Lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "29f9770a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Convert DESCRIPTION column to lowercase\n",
    "data['DESCRIPTION'] = data['DESCRIPTION'].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a5274",
   "metadata": {},
   "source": [
    "### Fixing Encoding Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5f2234af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv('data/train_data.txt', \n",
    "                       sep=':::', \n",
    "                       engine='python',\n",
    "                       encoding='utf-8',  # Ensure UTF-8 encoding\n",
    "                       on_bad_lines='skip',\n",
    "                       quotechar='\"', \n",
    "                       names=['ID', 'TITLE', 'GENRE', 'DESCRIPTION']\n",
    "                      )\n",
    "    print(\"Data loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b274acc",
   "metadata": {},
   "source": [
    "###  Remove Extra Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3023a854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_extra_whitespace(text):\n",
    "    words = text.split()\n",
    "    clean_words = [word.strip() for word in words]\n",
    "    clean_text = ' '.join(clean_words)\n",
    "    return clean_text\n",
    "\n",
    "# Apply the function to the DESCRIPTION column\n",
    "data['CLEAN_DESCRIPTION'] = data['DESCRIPTION'].apply(remove_extra_whitespace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f7f495d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample entries from DESCRIPTION column before cleaning:\n",
      "0     Listening in to a conversation between his do...\n",
      "1     A brother and sister with a past incestuous r...\n",
      "2     As the bus empties the students for their fie...\n",
      "3     To help their unemployed father make ends mee...\n",
      "4     The film's title refers not only to the un-re...\n",
      "Name: DESCRIPTION, dtype: object\n",
      "\n",
      "Sample entries from CLEAN_DESCRIPTION column after cleaning:\n",
      "0    Listening in to a conversation between his doc...\n",
      "1    A brother and sister with a past incestuous re...\n",
      "2    As the bus empties the students for their fiel...\n",
      "3    To help their unemployed father make ends meet...\n",
      "4    The film's title refers not only to the un-rec...\n",
      "Name: CLEAN_DESCRIPTION, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print sample entries before cleaning\n",
    "print(\"Sample entries from DESCRIPTION column before cleaning:\")\n",
    "print(data['DESCRIPTION'].head())\n",
    "\n",
    "# Print sample entries after cleaning\n",
    "print(\"\\nSample entries from CLEAN_DESCRIPTION column after cleaning:\")\n",
    "print(data['CLEAN_DESCRIPTION'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9dea0",
   "metadata": {},
   "source": [
    "### Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fe184d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled successfully.\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "assert not data.isnull().values.any(), \"Missing values are present in the data.\"\n",
    "\n",
    "# Print success message\n",
    "print(\"Missing values handled successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df010a9c",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "336cbfd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function to normalize numbers in a column\n",
    "def normalize_numbers_column(column):\n",
    "    number_pattern = r'\\b\\d[\\d,.]*\\b'\n",
    "    return column.str.replace(number_pattern, 'NUMBER', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0178d89c",
   "metadata": {},
   "source": [
    "### Non-informative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b6628002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/lilia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                       CLEAN_DESCRIPTION  \\\n",
       " 0      listening conversation doctor parents 10yearol...   \n",
       " 1      brother sister past incestuous relationship cu...   \n",
       " 2      bus empties students field trip museum natural...   \n",
       " 3      help unemployed father make ends meet edith tw...   \n",
       " 4      films title refers unrecovered bodies ground z...   \n",
       " ...                                                  ...   \n",
       " 54209  shortlived nbc live sitcom centered bonino wor...   \n",
       " 54210  next generation exploitation sisters kapa bay ...   \n",
       " 54211  ze bestaan echt standup comedy growing facing ...   \n",
       " 54212  walter vivian live country difficult time keep...   \n",
       " 54213  labor day weekend 1935 intense hurricane ever ...   \n",
       " \n",
       "        contains_non_informative  \n",
       " 0                         False  \n",
       " 1                         False  \n",
       " 2                         False  \n",
       " 3                         False  \n",
       " 4                         False  \n",
       " ...                         ...  \n",
       " 54209                     False  \n",
       " 54210                     False  \n",
       " 54211                     False  \n",
       " 54212                     False  \n",
       " 54213                     False  \n",
       " \n",
       " [54214 rows x 2 columns],\n",
       " {'Non-informative Words Removed': True})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the set of stop words the first time\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the stop words\n",
    "non_informative_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define the function to remove non-informative words\n",
    "def remove_non_informative(text):\n",
    "    # Split the text into words and remove non-informative words\n",
    "    return ' '.join(word for word in text.split() if word.lower() not in non_informative_words)\n",
    "\n",
    "# Assuming 'df' is your DataFrame and it has a column 'CLEAN_DESCRIPTION'\n",
    "# Apply the function to remove non-informative words from 'CLEAN_DESCRIPTION'\n",
    "df['CLEAN_DESCRIPTION'] = df['CLEAN_DESCRIPTION'].apply(remove_non_informative)\n",
    "\n",
    "# Check again for non-informative words in 'CLEAN_DESCRIPTION'\n",
    "df['contains_non_informative'] = df['CLEAN_DESCRIPTION'].apply(\n",
    "    lambda x: any(word.lower() in non_informative_words for word in x.split())\n",
    ")\n",
    "\n",
    "# Display the DataFrame to verify the removal\n",
    "display_df = df[['CLEAN_DESCRIPTION', 'contains_non_informative']]\n",
    "\n",
    "# Summarize the checks\n",
    "summary = {\n",
    "    'Non-informative Words Removed': not df['contains_non_informative'].any()\n",
    "}\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb120d",
   "metadata": {},
   "source": [
    "### checking cleanliness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5821e11f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No HTML tags were found in the DESCRIPTION column.\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the DESCRIPTION column before removing HTML tags\n",
    "original_length = len(data['DESCRIPTION'])\n",
    "\n",
    "# Apply the function to remove HTML tags\n",
    "data['DESCRIPTION'] = data['DESCRIPTION'].apply(remove_html_tags)\n",
    "# Get the length of the DESCRIPTION column after removing HTML tags\n",
    "cleaned_length = len(data['DESCRIPTION'])\n",
    "\n",
    "# Check if the lengths are different\n",
    "if original_length != cleaned_length:\n",
    "    print(\"HTML tags were present and successfully removed.\")\n",
    "else:\n",
    "    print(\"No HTML tags were found in the DESCRIPTION column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "922272a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Special characters were found in the DESCRIPTION column.\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the DESCRIPTION column before removing HTML tags\n",
    "original_length = len(data['DESCRIPTION'])\n",
    "\n",
    "# Apply the function to remove HTML tags\n",
    "data['DESCRIPTION'] = data['DESCRIPTION'].apply(remove_special_characters)\n",
    "# Get the length of the DESCRIPTION column after removing HTML tags\n",
    "cleaned_length = len(data['DESCRIPTION'])\n",
    "\n",
    "# Check if the lengths are different\n",
    "if original_length != cleaned_length:\n",
    "    print(\"Special characters were present and successfully removed.\")\n",
    "else:\n",
    "    print(\"No Special characters were found in the DESCRIPTION column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fcd65c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No emojis and symbols were found in the DESCRIPTION column.\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the DESCRIPTION column before removing HTML tags\n",
    "original_length = len(data['DESCRIPTION'])\n",
    "\n",
    "# Apply the function to remove HTML tags\n",
    "data['DESCRIPTION'] = data['DESCRIPTION'].apply(remove_emojis_and_symbols\n",
    ")\n",
    "# Get the length of the DESCRIPTION column after removing HTML tags\n",
    "cleaned_length = len(data['DESCRIPTION'])\n",
    "\n",
    "# Check if the lengths are different\n",
    "if original_length != cleaned_length:\n",
    "    print(\"emojis and symbols were present and successfully removed.\")\n",
    "else:\n",
    "    print(\"No emojis and symbols were found in the DESCRIPTION column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f88325cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All text in the CLEAN_DESCRIPTION column is in lowercase.\n"
     ]
    }
   ],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Apply the function to the DESCRIPTION column\n",
    "data['CLEAN_DESCRIPTION'] = data['DESCRIPTION'].apply(convert_to_lowercase)\n",
    "\n",
    "# Check if all text is converted to lowercase\n",
    "is_lowercase = (data['DESCRIPTION'].str.lower() == data['CLEAN_DESCRIPTION']).all()\n",
    "\n",
    "if is_lowercase:\n",
    "    print(\"All text in the CLEAN_DESCRIPTION column is in lowercase.\")\n",
    "else:\n",
    "    print(\"Not all text in the CLEAN_DESCRIPTION column is in lowercase.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c0881e-0869-49ec-ba8e-4581098ea496",
   "metadata": {},
   "source": [
    "### Tokenization, Stop Words Removal, and Handling Negations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c0579dd1-6a01-4ebd-846a-1954978aae2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenization, Stop Words Removal, and Handling Negations\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Removing non-alphanumeric characters\n",
    "    # This to make sure that we do not have like (film, 's, instead we will have films)\n",
    "    text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "    \n",
    "    # Tokenizing the description\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Removing stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Handling negations (e.g., \"not good\" becomes \"not_good\")\n",
    "    for i in range(len(filtered_tokens)):\n",
    "        if filtered_tokens[i] == 'not' and i + 1 < len(filtered_tokens):\n",
    "            filtered_tokens[i + 1] = 'not_' + filtered_tokens[i + 1]\n",
    "\n",
    "    return filtered_tokens\n",
    "\n",
    "# Applying the preprocessing function to the 'DESCRIPTION' column\n",
    "data['TOKENIZED_DESCRIPTION'] = data['CLEAN_DESCRIPTION'].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46d650",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c900532a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HTML Tags': False,\n",
       " 'Special Characters': False,\n",
       " 'Non-standard Symbols/Emojis': False,\n",
       " 'Lowercase Text': False,\n",
       " 'Tokenization Applied': True}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'data' is your DataFrame and it has a column 'CLEAN_DESCRIPTION'\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Check for HTML tags\n",
    "html_tag_pattern = re.compile(r'<[^>]+>')\n",
    "df['contains_html_tags'] = df['CLEAN_DESCRIPTION'].apply(lambda x: bool(html_tag_pattern.search(x)))\n",
    "\n",
    "# 2. Check for special characters\n",
    "special_chars_pattern = re.compile(r'[@#$%]')\n",
    "df['contains_special_chars'] = df['CLEAN_DESCRIPTION'].apply(lambda x: bool(special_chars_pattern.search(x)))\n",
    "\n",
    "# 3. Check for non-standard symbols or emojis\n",
    "non_standard_pattern = re.compile(r'[^\\w\\s,.!?;:\\-\\(\\)\\'\\\"/]')\n",
    "df['contains_non_standard_symbols'] = df['CLEAN_DESCRIPTION'].apply(lambda x: bool(non_standard_pattern.search(x)))\n",
    "\n",
    "# 4. Check for lowercase text\n",
    "df['is_lowercase'] = df['CLEAN_DESCRIPTION'].apply(lambda x: x.islower())\n",
    "\n",
    "# 5 Apply the function to remove non-informative words from 'CLEAN_DESCRIPTION'\n",
    "df['CLEAN_DESCRIPTION'] = df['CLEAN_DESCRIPTION'].apply(remove_non_informative)\n",
    "\n",
    "# Check again for non-informative words in 'CLEAN_DESCRIPTION'\n",
    "df['contains_non_informative'] = df['CLEAN_DESCRIPTION'].apply(\n",
    "    lambda x: any(word.lower() in non_informative_words for word in x.split())\n",
    ")\n",
    "\n",
    "# 6 check for tokenization\n",
    "df['is_tokenized'] = df['TOKENIZED_DESCRIPTION'].apply(lambda x: isinstance(x, list))\n",
    "\n",
    "\n",
    "# Display the DataFrame to verify the removal\n",
    "display_df = df[['CLEAN_DESCRIPTION', 'contains_non_informative']]\n",
    "\n",
    "# Now summarize the checks\n",
    "summary = {\n",
    "    'HTML Tags': df['contains_html_tags'].any(),\n",
    "    'Special Characters': df['contains_special_chars'].any(),\n",
    "    'Non-standard Symbols/Emojis': df['contains_non_standard_symbols'].any(),\n",
    "    'Lowercase Text': not df['is_lowercase'].all(),  \n",
    "    'Tokenization Applied': df['is_tokenized'].all(),\n",
    "}\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5a6f7b5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CLEAN_DESCRIPTION</th>\n",
       "      <th>TOKENIZED_DESCRIPTION</th>\n",
       "      <th>contains_html_tags</th>\n",
       "      <th>contains_special_chars</th>\n",
       "      <th>contains_non_standard_symbols</th>\n",
       "      <th>is_lowercase</th>\n",
       "      <th>contains_non_informative</th>\n",
       "      <th>is_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oscar et la dame rose (2009)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his do...</td>\n",
       "      <td>listening conversation doctor parents 10yearol...</td>\n",
       "      <td>[listening, conversation, doctor, parents, 10y...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cupid (1997)</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous r...</td>\n",
       "      <td>brother sister past incestuous relationship cu...</td>\n",
       "      <td>[brother, sister, past, incestuous, relationsh...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Young, Wild and Wonderful (1980)</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fie...</td>\n",
       "      <td>bus empties students field trip museum natural...</td>\n",
       "      <td>[bus, empties, students, field, trip, museum, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Secret Sin (1915)</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends mee...</td>\n",
       "      <td>help unemployed father make ends meet edith tw...</td>\n",
       "      <td>[help, unemployed, father, make, ends, meet, e...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Unrecovered (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>The films title refers not only to the unreco...</td>\n",
       "      <td>films title refers unrecovered bodies ground z...</td>\n",
       "      <td>[films, title, refers, unrecovered, bodies, gr...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54209</th>\n",
       "      <td>54210</td>\n",
       "      <td>\"Bonino\" (1953)</td>\n",
       "      <td>comedy</td>\n",
       "      <td>This shortlived NBC live sitcom centered on B...</td>\n",
       "      <td>shortlived nbc live sitcom centered bonino wor...</td>\n",
       "      <td>[shortlived, nbc, live, sitcom, centered, boni...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54210</th>\n",
       "      <td>54211</td>\n",
       "      <td>Dead Girls Don't Cry (????)</td>\n",
       "      <td>horror</td>\n",
       "      <td>The NEXT Generation of EXPLOITATION The siste...</td>\n",
       "      <td>next generation exploitation sisters kapa bay ...</td>\n",
       "      <td>[next, generation, exploitation, sisters, kapa...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54211</th>\n",
       "      <td>54212</td>\n",
       "      <td>Ronald Goedemondt: Ze bestaan echt (2008)</td>\n",
       "      <td>documentary</td>\n",
       "      <td>Ze bestaan echt is a standup comedy about gro...</td>\n",
       "      <td>ze bestaan echt standup comedy growing facing ...</td>\n",
       "      <td>[ze, bestaan, echt, standup, comedy, growing, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54212</th>\n",
       "      <td>54213</td>\n",
       "      <td>Make Your Own Bed (1944)</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Walter and Vivian live in the country and hav...</td>\n",
       "      <td>walter vivian live country difficult time keep...</td>\n",
       "      <td>[walter, vivian, live, country, difficult, tim...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54213</th>\n",
       "      <td>54214</td>\n",
       "      <td>Nature's Fury: Storm of the Century (2006)</td>\n",
       "      <td>history</td>\n",
       "      <td>On Labor Day Weekend 1935 the most intense hu...</td>\n",
       "      <td>labor day weekend 1935 intense hurricane ever ...</td>\n",
       "      <td>[labor, day, weekend, 1935, intense, hurricane...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54214 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                         TITLE          GENRE  \\\n",
       "0          1                 Oscar et la dame rose (2009)          drama    \n",
       "1          2                                 Cupid (1997)       thriller    \n",
       "2          3             Young, Wild and Wonderful (1980)          adult    \n",
       "3          4                        The Secret Sin (1915)          drama    \n",
       "4          5                       The Unrecovered (2007)          drama    \n",
       "...      ...                                           ...            ...   \n",
       "54209  54210                              \"Bonino\" (1953)         comedy    \n",
       "54210  54211                  Dead Girls Don't Cry (????)         horror    \n",
       "54211  54212    Ronald Goedemondt: Ze bestaan echt (2008)    documentary    \n",
       "54212  54213                     Make Your Own Bed (1944)         comedy    \n",
       "54213  54214   Nature's Fury: Storm of the Century (2006)        history    \n",
       "\n",
       "                                             DESCRIPTION  \\\n",
       "0       Listening in to a conversation between his do...   \n",
       "1       A brother and sister with a past incestuous r...   \n",
       "2       As the bus empties the students for their fie...   \n",
       "3       To help their unemployed father make ends mee...   \n",
       "4       The films title refers not only to the unreco...   \n",
       "...                                                  ...   \n",
       "54209   This shortlived NBC live sitcom centered on B...   \n",
       "54210   The NEXT Generation of EXPLOITATION The siste...   \n",
       "54211   Ze bestaan echt is a standup comedy about gro...   \n",
       "54212   Walter and Vivian live in the country and hav...   \n",
       "54213   On Labor Day Weekend 1935 the most intense hu...   \n",
       "\n",
       "                                       CLEAN_DESCRIPTION  \\\n",
       "0      listening conversation doctor parents 10yearol...   \n",
       "1      brother sister past incestuous relationship cu...   \n",
       "2      bus empties students field trip museum natural...   \n",
       "3      help unemployed father make ends meet edith tw...   \n",
       "4      films title refers unrecovered bodies ground z...   \n",
       "...                                                  ...   \n",
       "54209  shortlived nbc live sitcom centered bonino wor...   \n",
       "54210  next generation exploitation sisters kapa bay ...   \n",
       "54211  ze bestaan echt standup comedy growing facing ...   \n",
       "54212  walter vivian live country difficult time keep...   \n",
       "54213  labor day weekend 1935 intense hurricane ever ...   \n",
       "\n",
       "                                   TOKENIZED_DESCRIPTION  contains_html_tags  \\\n",
       "0      [listening, conversation, doctor, parents, 10y...               False   \n",
       "1      [brother, sister, past, incestuous, relationsh...               False   \n",
       "2      [bus, empties, students, field, trip, museum, ...               False   \n",
       "3      [help, unemployed, father, make, ends, meet, e...               False   \n",
       "4      [films, title, refers, unrecovered, bodies, gr...               False   \n",
       "...                                                  ...                 ...   \n",
       "54209  [shortlived, nbc, live, sitcom, centered, boni...               False   \n",
       "54210  [next, generation, exploitation, sisters, kapa...               False   \n",
       "54211  [ze, bestaan, echt, standup, comedy, growing, ...               False   \n",
       "54212  [walter, vivian, live, country, difficult, tim...               False   \n",
       "54213  [labor, day, weekend, 1935, intense, hurricane...               False   \n",
       "\n",
       "       contains_special_chars  contains_non_standard_symbols  is_lowercase  \\\n",
       "0                       False                          False          True   \n",
       "1                       False                          False          True   \n",
       "2                       False                          False          True   \n",
       "3                       False                          False          True   \n",
       "4                       False                          False          True   \n",
       "...                       ...                            ...           ...   \n",
       "54209                   False                          False          True   \n",
       "54210                   False                          False          True   \n",
       "54211                   False                          False          True   \n",
       "54212                   False                          False          True   \n",
       "54213                   False                          False          True   \n",
       "\n",
       "       contains_non_informative  is_tokenized  \n",
       "0                         False          True  \n",
       "1                         False          True  \n",
       "2                         False          True  \n",
       "3                         False          True  \n",
       "4                         False          True  \n",
       "...                         ...           ...  \n",
       "54209                     False          True  \n",
       "54210                     False          True  \n",
       "54211                     False          True  \n",
       "54212                     False          True  \n",
       "54213                     False          True  \n",
       "\n",
       "[54214 rows x 12 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29023858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM_ENV",
   "language": "python",
   "name": "dm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
